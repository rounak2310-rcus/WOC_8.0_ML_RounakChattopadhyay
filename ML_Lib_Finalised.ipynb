{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4lYkVB3TpC13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is a class for normalising/standardising data.\n",
        "class Modify():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def fit(self, X):\n",
        "    self.min = X.min(axis=0)\n",
        "    self.max = X.max(axis=0)\n",
        "    self.mean = X.mean(axis=0)\n",
        "    self.err = 1e-8\n",
        "    self.std = X.std(axis=0) + self.err\n",
        "    self.range = self.max-self.min + self.err\n",
        "\n",
        "  def norm(self, X):\n",
        "    try:\n",
        "      return (X-self.min)/self.range\n",
        "    except Exception as error_type:\n",
        "      print(\"Error: \", error_type)\n",
        "\n",
        "  def z_score(self, X):\n",
        "    try:\n",
        "      return (X-self.mean)/self.std\n",
        "    except Exception as error_type:\n",
        "      print(\"Error: \", error_type)"
      ],
      "metadata": {
        "id": "NZR9npGApQk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementation of optimisers.\n",
        "class optimiser:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def update(self):\n",
        "    raise NotImplementedError\n",
        "\n",
        "class gradient_descent(optimiser):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def update(self, gradient):\n",
        "    return -gradient\n",
        "\n",
        "class momentum(optimiser):\n",
        "  def __init__(self, beta = 0.9):\n",
        "    self.beta = beta\n",
        "    self.v = None\n",
        "\n",
        "  def update(self, gradient):\n",
        "    if self.v is None:\n",
        "      self.v = np.zeros_like(gradient)\n",
        "    self.v = self.beta * self.v + (1-self.beta) * gradient\n",
        "    return -self.v\n",
        "\n",
        "class rmsprop(optimiser):\n",
        "  def __init__(self, beta = 0.9):\n",
        "    self.beta = beta\n",
        "    self.s = None\n",
        "\n",
        "  def update(self, gradient):\n",
        "    if self.s is None:\n",
        "      self.s = np.zeros_like(gradient)\n",
        "    self.s = self.beta * self.s + (1-self.beta) * (gradient*gradient)\n",
        "    return -gradient/(np.sqrt(self.s)+1e-8)\n",
        "\n",
        "class adam(optimiser):\n",
        "  def __init__(self, beta1 = 0.9, beta2 = 0.999):\n",
        "    self.beta1 = beta1\n",
        "    self.beta2 = beta2\n",
        "    self.m = None\n",
        "    self.v = None\n",
        "    self.t = 1\n",
        "\n",
        "  def update(self, gradient):\n",
        "    if self.m is None:\n",
        "      self.m = np.zeros_like(gradient)\n",
        "    if self.v is None:\n",
        "      self.v = np.zeros_like(gradient)\n",
        "    self.m = self.beta1 * self.m + (1-self.beta1) * gradient\n",
        "    self.v = self.beta2 * self.v + (1-self.beta2) * (gradient*gradient)\n",
        "    m_hat = self.m/(1-(self.beta1**self.t))\n",
        "    v_hat = self.v/(1-(self.beta2**self.t))\n",
        "    self.t+= 1\n",
        "    return -m_hat/(np.sqrt(v_hat)+1e-8)"
      ],
      "metadata": {
        "id": "WnCO7dmcxg-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "serdQhtio-Ki"
      },
      "outputs": [],
      "source": [
        "#Single Variable Linear Regression that uses closed form solution\n",
        "class SimpleLin_Reg():\n",
        "  def __init__(self):\n",
        "    self.w = None\n",
        "    self.b = None\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    try:\n",
        "      self.w = ((X*Y).mean()-(X.mean()*Y.mean()))/((X*X).mean()-(X.mean()*X.mean()))\n",
        "      self.b = Y.mean() - self.w*X.mean()\n",
        "\n",
        "      return self.w, self.b\n",
        "    except Exception as error_type:\n",
        "      print(\"Error: \", error_type)\n",
        "\n",
        "  def predict(self, X):\n",
        "    return round(self.w*X+self.b, 4)\n",
        "\n",
        "  def plot(self, X, Y):\n",
        "    plt.scatter(X, Y, color='blue')\n",
        "    plt.grid(1)\n",
        "    self.w, self.b = self.fit(X, Y)\n",
        "    plt.xlabel(\"X\")\n",
        "    plt.ylabel(\"Y\")\n",
        "    plt.title(\"Y= \"+str(round(self.w,4))+\" X + \"+str(round(self.b,4)))\n",
        "    plt.plot(X, self.predict(X), color='red')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Multivariable Linear Regression\n",
        "class multivLin_Reg():\n",
        "    def __init__(self, lr=0.1, p=1000):\n",
        "        self.lr = lr\n",
        "        self.p = p\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        X = np.array(X)\n",
        "        Y = np.array(Y).reshape(-1,1)\n",
        "        self.modify = Modify()\n",
        "        self.modify.fit(X)\n",
        "        X = self.modify.z_score(X)\n",
        "        m, n = X.shape\n",
        "        self.w = np.zeros(n).reshape(n,1)\n",
        "        self.b = 0\n",
        "        P = np.linspace(0, self.p, self.p+1)\n",
        "        L = []\n",
        "\n",
        "        for u in range(self.p):\n",
        "            y_pred = (X @ self.w + self.b).reshape(-1, 1)\n",
        "            loss = np.mean((y_pred - Y)**2)\n",
        "            L.append(loss)\n",
        "\n",
        "            if (u>10) and (u%10==0):\n",
        "              if (abs(L[u-10]-L[u])<0.1):\n",
        "                print(f\"Epoch: {u}\")\n",
        "                break\n",
        "\n",
        "            dW = (1/m) * (X.T @ (y_pred - Y))\n",
        "            dB = (1/m) * np.sum(y_pred - Y)\n",
        "\n",
        "            self.w -= self.lr * dW\n",
        "            self.b -= self.lr * dB\n",
        "\n",
        "        plt.plot(P[:u+1], L)\n",
        "        R2 = 1 - (np.sum((y_pred - Y)**2)/np.sum((Y - np.mean(Y))**2))\n",
        "        print(f\"R2 evaluation: {R2}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.modify.z_score(np.array(X)) @ self.w + self.b"
      ],
      "metadata": {
        "id": "cZqQW8-K4OsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "class Log_Reg():\n",
        "    def __init__(self, lr=0.5, p=1000):\n",
        "        self.lr = lr\n",
        "        self.p = p\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        self.modify = Modify()\n",
        "        X = np.array(X)\n",
        "        self.modify.fit(X)\n",
        "        X = self.modify.z_score(X)\n",
        "        Y = np.array(Y).reshape(-1, 1)\n",
        "        m, n = X.shape\n",
        "        self.w = np.zeros(n).reshape(n, 1)\n",
        "        self.b = 0\n",
        "        P = np.linspace(0, self.p, self.p+1)\n",
        "        L = []\n",
        "        for u in range(self.p):\n",
        "            z = X @ self.w + self.b\n",
        "            z = z.reshape(-1, 1)\n",
        "            y = 1 / (1 + np.exp(-z))\n",
        "\n",
        "            loss = -np.mean(Y * np.log(y + self.modify.err) + (1 - Y) * np.log(1 - y + self.modify.err))\n",
        "            L.append(loss)\n",
        "            if (u>10) and (u%10==0):\n",
        "              if (abs(L[u-10]-L[u])<0.001):\n",
        "                print(f\"Epoch: {u}\")\n",
        "                break\n",
        "\n",
        "            dJ_dw = (1/m) * (X.T @ (y - Y))\n",
        "            dJ_db = (1/m) * np.sum(y - Y)\n",
        "\n",
        "            self.w -= self.lr * dJ_dw\n",
        "            self.b -= self.lr * dJ_db\n",
        "        plt.plot(P[:u+1], L)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = self.modify.z_score(np.array(X))\n",
        "        z = X @ self.w + self.b\n",
        "        y = 1 / (1 + np.exp(-z))\n",
        "        return np.where(y > 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "UPU6k3dz2AJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Polynomial Regression of a single Variable nth degree\n",
        "class Poly_Reg():\n",
        "  def __init__(self, degree= 3):\n",
        "    self.degree = degree\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    X = X.reshape(-1,1)\n",
        "    m = X.shape[0]\n",
        "    self.w = np.zeros(self.degree+1).reshape(self.degree+1, 1)\n",
        "    Z = np.zeros(m*(self.degree+1)).reshape(-1, self.degree+1)\n",
        "    for i in range(m):\n",
        "      for j in range(self.degree+1):\n",
        "        Z[i,j] = np.power(X[i].flatten()[0], j)\n",
        "\n",
        "    self.w = np.linalg.inv(Z.T @ Z) @ Z.T @ Y\n",
        "\n",
        "  def predict(self, X):\n",
        "    X = X.reshape(-1, 1)\n",
        "    m = X.shape[0]\n",
        "    Z = np.zeros(m*(self.degree+1)).reshape(-1, self.degree+1)\n",
        "    for i in range(m):\n",
        "      for j in range(self.degree+1):\n",
        "        Z[i, j] = np.power(X[i].flatten()[0], j)\n",
        "\n",
        "    return (Z @ self.w).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "s4d_YBPqqqxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Trees\n",
        "def entropy(Y):\n",
        "  classes, count = np.unique(Y, return_counts=True)\n",
        "  p = count / count.sum()\n",
        "  return -np.sum(p * np.log2(p))\n",
        "\n",
        "def info_gain(left, right, parent):\n",
        "  return entropy(parent) - ((len(left)/len(parent)) * entropy(left) + (len(right)/len(parent)) * entropy(right))\n",
        "\n",
        "def split_dataset(X, Y, feature_index, threshold):\n",
        "  left_bool = (X[:, feature_index] <= threshold).reshape(-1,)\n",
        "  right_bool = (X[:, feature_index] > threshold).reshape(-1,)\n",
        "\n",
        "  X_left = X[left_bool]\n",
        "  X_right = X[right_bool]\n",
        "\n",
        "  Y_left = Y[left_bool]\n",
        "  Y_right = Y[right_bool]\n",
        "\n",
        "  return X_left, X_right, Y_left, Y_right\n",
        "\n",
        "def best_split(X, Y):\n",
        "  max_info_gain = 0\n",
        "  best_feature = 0\n",
        "  best_threshold = 0\n",
        "  for i in range(0, X.shape[1]):\n",
        "    Threshold_array = np.sort(np.unique(X[:, i])).astype(float)\n",
        "    for j in range(0, Threshold_array.shape[0]-1):\n",
        "      Threshold_array[j] = (Threshold_array[j] + Threshold_array[j+1])/2\n",
        "      X_left, X_right, Y_left, Y_right = split_dataset(X, Y, i, Threshold_array[j])\n",
        "      ig = info_gain(Y_left, Y_right, Y)\n",
        "      if (max_info_gain < ig):\n",
        "        max_info_gain = ig\n",
        "        best_feature = i\n",
        "        best_threshold = Threshold_array[j]\n",
        "\n",
        "  return best_feature, best_threshold, max_info_gain\n",
        "\n",
        "class Node():\n",
        "  def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
        "    self.feature_index = feature_index\n",
        "    self.threshold = threshold\n",
        "    self.left = left\n",
        "    self.right = right\n",
        "    self.info_gain = info_gain\n",
        "    self.value = value\n",
        "\n",
        "def build_tree(X, Y):\n",
        "  root = Node()\n",
        "  root.feature_index, root.threshold, root.info_gain = best_split(X, Y)\n",
        "  A, B = np.unique(Y, return_counts=True)\n",
        "  if (len(A) == 1):\n",
        "    root.value = A[0]\n",
        "    return root\n",
        "  if (root.info_gain == 0):\n",
        "    root.value = A[np.argmax(B)]\n",
        "    return root\n",
        "  X_left, X_right, Y_left, Y_right = split_dataset(X, Y, root.feature_index, root.threshold)\n",
        "  if (X_left.size == 0 or X_right.size == 0):\n",
        "    root.value = A[np.argmax(B)]\n",
        "    return root\n",
        "  root.left = build_tree(X_left, Y_left)\n",
        "  root.right = build_tree(X_right, Y_right)\n",
        "  return root\n",
        "\n",
        "def predict(root, X):\n",
        "  if (root.value != None):\n",
        "    return root.value\n",
        "  if (X[root.feature_index] <= root.threshold):\n",
        "    return predict(root.left, X)\n",
        "  else:\n",
        "    return predict(root.right, X)\n",
        "\n",
        "class DecisionTree():\n",
        "  def __init__(self):\n",
        "    self.root = None\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    self.root = build_tree(X, Y)\n",
        "    return self.root\n",
        "\n",
        "  def predict(self, X):\n",
        "    return predict(self.root, X)"
      ],
      "metadata": {
        "id": "-2PMGqUVcWkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "class KNN():\n",
        "  def __init__(self, K = 4):\n",
        "    self.K = K\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "    self.modify = Modify()\n",
        "    self.modify.fit(X)\n",
        "    self.A = self.modify.norm(X)\n",
        "\n",
        "\n",
        "  def predict(self, P):\n",
        "    B = self.modify.norm(P).reshape(1, -1)\n",
        "    if (B.shape[1]==self.A.shape[1]):\n",
        "      C = abs(self.A-B).sum(axis=1)\n",
        "      print(C.shape)\n",
        "      idx = np.argsort(C)[:self.K]\n",
        "      U, V = np.unique(self.Y[idx], return_counts=True)\n",
        "      return U[np.argmax(V)]\n",
        "    else:\n",
        "      B = B.reshape(-1, self.A.shape[1])\n",
        "      G = []\n",
        "      for r in range(B.shape[0]):\n",
        "        C = abs(self.A-B[:, r]).sum(axis=1)\n",
        "        idx = np.argsort(C)[:self.K]\n",
        "        U, V = np.unique(self.Y[idx], return_counts=True)\n",
        "        G.append(U[np.argmax(V)])\n",
        "      return G"
      ],
      "metadata": {
        "id": "e9KFYePDmaQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#K Means Classification\n",
        "class K_Means():\n",
        "  def __init__(self, clusters=4, iterations=100):\n",
        "    self.K = clusters\n",
        "    self.p = iterations\n",
        "\n",
        "  def distance(self, x, centroids):\n",
        "    return np.linalg.norm(x-centroids, axis=1)\n",
        "\n",
        "  def fit(self, X):\n",
        "    self.X = np.array(X)\n",
        "    m, n = self.X.shape\n",
        "    self.modify = Modify()\n",
        "    self.modify.fit(self.X)\n",
        "    self.X = self.modify.z_score(self.X)\n",
        "\n",
        "    centroids = []\n",
        "    centroids.append(self.X[np.random.choice(m)])\n",
        "    for _ in range(1, self.K):\n",
        "      distances = np.array([min(np.linalg.norm(np.array(x) - np.array(c)) ** 2 for c in centroids) for x in self.X])\n",
        "      probs = distances / np.sum(distances)\n",
        "      centroids.append(self.X[np.random.choice(m, p=probs)])\n",
        "    centroids = np.array(centroids)\n",
        "\n",
        "    for itr in range(self.p):\n",
        "      cluster_set = [[] for j in range(self.K)]\n",
        "      for x in self.X:\n",
        "        dist = self.distance(x, centroids)\n",
        "        cluster = np.argmin(dist)\n",
        "        cluster_set[cluster].append(x)\n",
        "\n",
        "      new_centroids = []\n",
        "      for i, cluster in enumerate(cluster_set):\n",
        "        if len(cluster) == 0:\n",
        "          distances = np.linalg.norm(self.X - centroids[i], axis=1)\n",
        "          new_centroids.append(self.X[np.random.choice(m)])\n",
        "        else:\n",
        "          new_centroids.append(np.mean(cluster, axis=0))\n",
        "\n",
        "      new_centroids = np.array(new_centroids)\n",
        "\n",
        "      if np.allclose(centroids, new_centroids, atol=1e-6):\n",
        "        break\n",
        "      centroids = new_centroids\n",
        "\n",
        "    self.centroids = centroids\n",
        "    if (n==2):\n",
        "      plt.scatter(self.X[:,0], self.X[:,1], color='blue')\n",
        "      plt.scatter(centroids[:,0], centroids[:,1], color='red')\n",
        "      plt.show()\n",
        "\n",
        "  def predict(self, X):\n",
        "    X = self.modify.z_score(np.array(X))\n",
        "    labels = []\n",
        "    for x in X:\n",
        "        labels.append(np.argmin(self.distance(x, self.centroids)))\n",
        "    return np.array(labels)\n"
      ],
      "metadata": {
        "id": "EgFj_dFEENz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Neural Networkss\n",
        "class Layer:\n",
        "  def forward(self, X):\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def backward(self, d_out):\n",
        "    raise NotImplementedError\n",
        "\n",
        "def he(shape):\n",
        "  return np.random.randn(*shape) * np.sqrt(2/shape[0])\n",
        "\n",
        "def xavier(shape):\n",
        "  return np.random.randn(*shape) * np.sqrt(1/shape[0])\n",
        "\n",
        "class Linear(Layer):\n",
        "  def __init__(self, in_features, out_features, optimiser, weight_init):\n",
        "    self.inf = in_features\n",
        "    self.outf = out_features\n",
        "    self.W = weight_init((in_features, out_features)).reshape(in_features, out_features)\n",
        "    self.b = np.zeros(out_features).reshape(-1, out_features)\n",
        "    self.dW = None\n",
        "    self.db = None\n",
        "    self.optimiser_W = optimiser()\n",
        "    self.optimiser_b = optimiser()\n",
        "\n",
        "  def forward(self, X):\n",
        "    self.X = np.array(X).reshape(-1, self.inf)\n",
        "    return (self.X @ self.W + self.b).reshape(-1, self.outf)\n",
        "\n",
        "  def backward(self, dZ):\n",
        "    self.dW = (self.X.T @ dZ).reshape(self.inf, self.outf)\n",
        "    self.db = np.sum(dZ, axis=0).reshape(self.b.shape)\n",
        "    return dZ @ self.W.T\n",
        "\n",
        "  def update(self, lr=0.01):\n",
        "    self.lr = lr\n",
        "    self.W += self.lr * self.optimiser_W.update(self.dW)\n",
        "    self.b += self.lr * self.optimiser_b.update(self.db)\n",
        "\n",
        "\n",
        "class ReLU(Layer):\n",
        "  def forward(self, Z):\n",
        "    self.Z = Z\n",
        "    return (Z > 0) * Z\n",
        "\n",
        "  def backward(self, dA):\n",
        "    return dA * (self.Z > 0)\n",
        "\n",
        "class Sigmoid(Layer):\n",
        "  def forward(self, Z):\n",
        "    self.Z = Z\n",
        "    self.A = 1 / (1 + np.exp(-Z))\n",
        "    return self.A\n",
        "\n",
        "  def backward(self, dA):\n",
        "    return dA * self.A * (1 - self.A)\n",
        "\n",
        "\n",
        "class MSELoss:\n",
        "  def forward(self, y_pred, y_true):\n",
        "    self.y_pred = y_pred\n",
        "    self.y_true = y_true\n",
        "    return np.mean((y_pred - y_true) ** 2)\n",
        "\n",
        "  def backward(self):\n",
        "    return 2 * (self.y_pred - self.y_true) / self.y_pred.shape[0]\n",
        "\n",
        "\n",
        "class Network:\n",
        "  def __init__(self, layers, lr=0.01):\n",
        "    self.layers = layers\n",
        "    self.lr = lr\n",
        "\n",
        "  def forward(self, X):\n",
        "    for layer in self.layers:\n",
        "      X = layer.forward(X)\n",
        "    return X\n",
        "\n",
        "  def backward(self, dY):\n",
        "    for layer in reversed(self.layers):\n",
        "      dY = layer.backward(dY)\n",
        "\n",
        "  def update(self):\n",
        "    for layer in self.layers:\n",
        "      if hasattr(layer, \"update\"):\n",
        "        layer.update(self.lr)"
      ],
      "metadata": {
        "id": "Dordp37VfFTi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}